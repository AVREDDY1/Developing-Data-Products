---
title: "Predicting Exercise Correctness with Random Forests"
author: "Anshuman Reddy"
date: "April 13, 2016"
output: html_document
---

# Synopsis

This assignment uses data collected by fitness devices to predict the correctness of exercise form with each participant's form is broken down into one of six classes. It uses the method of random forests to predict the category of 20 other participants.

## Preliminaries

This analysis uses the `caret` and `randomForest` libraries for prediction but also sets the seed.

```{r, message=FALSE}
library(caret)
library(randomForest)

set.seed(12345)
```

## Getting and cleaning the data

The CSVs are downloaded into data frames directly from the URL.

```{r, cache=TRUE}
train_url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test_url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

training <- read.csv(url(train_url), na.strings = c('', 'NA', '#DIV/0!'))  # there are many missing values in the
                                                                           # training set
testing <- read.csv(url(test_url))
```

The first 7 columns are discard because they have no useful information.

```{r}
training <- training[, -(1:7)]
testing  <- testing[, -(1:7)]
```

Any columns that have  missing values are also removed. This stil leaves 52 variables, enough for the algorithm to function.

```{r}
is_data_rich <- function(vec, allowed_na_proportion = 0) {
    mean(is.na(vec)) <= allowed_na_proportion
}

data_rich_cols <- apply(training, 2, is_data_rich)
training <- training[, data_rich_cols]

dim(training)
```

## Training the data

The `caret` package breaks off part of the training set for validation purposes later on.

```{r}
in_train <- createDataPartition(training$classe, list=F, p=.6)

train_train <- training[in_train, ]
train_validate <- training[-in_train, ]
```

The method of random forests is used to train the "classe" variable (a factor with labels A:E that identifies form correctness category) on the rest of the data. `ntree` is set to 10 in order to speed up the algorithm. While reducing the number of trees, growth may lead to a less accurate prediction. uUltimately, this loss is minor and the model is still highly predictive, as will be demonstrated later in the analysis.

```{r, cache=T}
fit <- train(classe ~ ., train_train, method="rf", ntree=10)
```

## Validating the data

To estimate the out-of-sample error rate, the confusion matrix between the predicted classe variable and actual class variable of the validation set is analyzed.

```{r}
confusionMatrix(train_validate$classe, predict(fit, train_validate))
```

Based on the accuracy of the model on the validation set, the expected  out-of-sample error rate is about 0.9878.

## Predictions of the test set

The model is used to  predict 20 additional cases. The results corresond with the information on the Coursera Project Website.

```{r}
cols_in_train <- names(testing) %in% names(training)  # ensure we provide the expected input to the model

predict(fit, testing[, cols_in_train])
```